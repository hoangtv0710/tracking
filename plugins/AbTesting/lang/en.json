{
  "AbTesting": {
    "AbTesting": "A/B Testing",
    "PluginDescription": "A/B Testing plugin",
    "NExperiments": "%s A/B tests",
    "ColumnConversionsPerVisit": "Conversions per visit",
    "ColumnRevenuePerVisit": "Revenue per visit",
    "ColumnOrdersPerVisit": "Orders per visit",
    "ColumnOrdersRevenuePerVisit": "Revenue per visit (from orders)",
    "ColumnDetectedEffect": "Detected effect",
    "ColumnDetectedEffectDocumentation": "The percentage of change compared to the original version. A positive detected effect means the variation is performing better than the original version while a negative detected effect means the variation is performing worse than the original version.",
    "ColumnRemainingVisitors": "Remaining visitors",
    "ColumnRemainingVisitorsDocumentation": "The number of additional unique visitors needed to enter the A/B test in order to be able to draw conclusive results.",
    "ColumnSignificanceRate": "Statistical Significance",
    "ColumnSignificanceRateDocumentation": "The higher the statistical significance percentage, the more likely it is that the detected effect is real, repeatable and not due to randomness.",
    "ColumnTimeOnSite": "Time on website",
    "ColumnTotalConversions": "Total Conversions",
    "ColumnTotalConversionsPerVisit": "Conversions per visit",
    "ColumnTotalRevenue": "Total Revenue",
    "ColumnTotalRevenuePerVisit": "Revenue per visit",
    "ColumnVisitsDocumentation": "The number of visits which your A/B test has received. All visits of a visitor who has entered the A/B test once count towards this visit metric. Therefore this number is usually higher than the number of \"actively entered visits\".",
    "ColumnVisitsEnteredDocumentation": "The number of visits where a visitor has entered a target page of this A/B test.",
    "ColumnUniqueVisitorsDocumentation": "The number of unique visitors that have entered your A/B test.",
    "ColumnBounceRateDocumentation": "The percentage of visits that only had a single pageview. This means, that the visitor left the target page directly after entering the A/B test.",
    "ColumnBouncesDocumentation": "The number of visits that started and ended when they entered an A/B test target page. This means that the visitor left after viewing only a target page.",
    "ChooseExperiment": "Choose A/B Test",
    "EcommerceOrders": "Ecommerce Orders",
    "EcommerceOrdersRevenue": "Ecommerce Orders Revenue",
    "ConclusionNoVariationRecordedYet": "No A/B test activity has been recorded yet for any variation. It appears no visitor has entered the A/B test. Maybe the A/B test code needs to be embedded into your project.",
    "ConclusionWinningVariation": "There is a variation that is performing significantly better than the original version and it has met the expected Minimum Detectable Effect (MDE) of %1$s.",
    "ConclusionSignificantVariation": "There is a variation that is performing significantly better than the original version but it has not met the expected Minimum Detectable Effect (MDE) of %1$s.",
    "ConclusionLosingVariation": "There is a variation that is performing significantly worse than the original version.",
    "ConclusionNoVariationHasEnoughVisitors": "More visitors are needed to draw conclusive results.",
    "ConclusionNoVariationIsSignificant": "No variation has currently enough significance to draw conclusive results.",
    "ConclusionNoConclusion": "To draw conclusive results a variation needs to have no remaining visitors and be statistically significant.",
    "NameOriginalVariation": "Original",
    "ErrorCreateNoUrlDefined": "Please enter an URL to define on which pages the A/B test should be activated.",
    "ErrorXNotProvided": "Please provide a value for \"%1$s\".",
    "ErrorXTooLong": "\"%1$s\" is too long, max %2$s characters are allowed.",
    "ErrorXTooLow": "\"%1$s\" is too low, minimum allowed value is %2$s.",
    "ErrorXTooHigh": "\"%1$s\" is too high, maximum allowed value is %2$s.",
    "ErrorXNotANumber": "\"%1$s\" has to be a number.",
    "ErrorXNotWhitelisted": "The value for \"%1$s\" is not allowed, use one of: %2$s.",
    "ErrorXContainsWhitespace": "The \"%1$s\" is not allowed to contain any whitespace.",
    "ErrorXContainsOnlyNumbers": "The \"%1$s\" is not allowed to contain only numbers, please use at least one letter.",
    "ErrorXOnlyAlNumDash": "Special characters for \"%1$s\" are not allowed.",
    "ErrorXNotInFuture": "\"%1$s\" must be in the future.",
    "ErrorXLaterThanY": "\"%1$s\" is later than \"%2$s\".",
    "ErrorXLaterThanYButEqual": "\"%1$s\" must be later than \"%2$s\" but they are equal.",
    "ErrorNotEnabledForExperiment": "The given \"%1$s\" is not enabled for this A/B test.",
    "ErrorNotAnArray": "\"%1$s\" has to be an array.",
    "ErrorInnerIsNotAnArray": "Each \"%1$s\" within \"%2$s\" has to be an array.",
    "ErrorArrayMissingKey": "Missing array key \"%1$s\" in \"%2$s\" at position \"%3$s\".",
    "ErrorArrayMissingValue": "Missing value for array key \"%1$s\" in \"%2$s\" at position \"%3$s\".",
    "ErrorInvalidValue": "Invalid value for \"%1$s\" provided (\"%2$s\").",
    "ErrorExperimentDoesNotExist": "The requested A/B test does not exist",
    "ErrorExperimentNameIsAlreadyInUse": "The A/B test name is already in use by another A/B test.",
    "ErrorExperimentAlreadyStarted": "The A/B test cannot be started as it has been started already.",
    "ErrorExperimentCannotBeFinished": "This A/B test cannot be finished as it has been finished already.",
    "ErrorExperimentCannotBeUpdatedBecauseArchived": "This A/B test cannot be updated because it has been archived.",
    "ErrorVariationNameOriginalNotAllowed": "The variation name \"Original\" is a reserved variation name and cannot be used.",
    "ErrorInvalidRegExp": "The regular expression \"%1$s\" does not have a valid format.",
    "ErrorNotValidUrl": "%1$s is not a valid URL. Make sure it starts for example with http://",
    "FieldSuccessMetricsLabel": "Select one or more success metrics",
    "FieldSuccessMetricsHelp1": "Success metrics help you to measure which of the variations is most successful and should be used in the future.",
    "FieldSuccessMetricsHelp2": "You can select one or multiple metrics to validate your hypothesis. Matomo will show a report comparing the different variations for each of your chosen metrics.",
    "FieldSuccessMetricsHelp3": "We recommend not to change any of your selected success metrics once an A/B test has been started as it could lead to misinterpretations about the results.",
    "FieldIncludedTargetsLabel": "A visitor will enter the A/B test when",
    "FieldIncludedTargetsHelp2": "Targets allow you to define on which pages a visitor should enter this A/B test. You can define one or more conditions. For example you can define to run an A/B test whenever the URL or path equals a certain value or only if a certain URL parameter is present in the URL. A visitor will enter the A/B test when any of the conditions are met, not if all of them are met. All conditions will be evaluated case insensitive.",
    "FieldExcludedTargetsLabel": "A visitor will not enter the A/B test when",
    "FieldExcludedTargetsHelp": "By defining exclusions you can restrict on which pages a visitor will not enter this A/B test. If a page matches any of these conditions, a visitor will not enter this A/B test.",
    "FieldRedirectHelp1": "If you want to redirect your users to a different page when they enter this A/B test, you can optionally configure a redirect URL for each variation. This is useful when you run an A/B test in the browser using our JavaScript A/B testing framework. If you configure a URL, the \"Embed Code\" will automatically include the tracking code to perform a redirect so you only need to copy / paste the tracking code into your project and you are done.",
    "FieldRedirectHelp2": "If the redirects should not be executed on all pages, we recommend to make sure to specify on which pages a redirect should be executed under \"Target Pages\".",
    "FieldRedirectHelp3": "With our %sPHP A/B testing framework%s you can also redirect users server side in your PHP project.",
    "ClickToCreateNewGoal": "Click here to create a new goal if a success metric is missing from the list.",
    "FormScheduleIntroduction": "By default an A/B test will start as soon as this A/B test is embedded into your project and will end as soon as you manually finish it. Alternatively you can schedule a start and finish date for this A/B test.",
    "FieldScheduleExperimentStartLabel": "Start A/B test on",
    "FieldScheduleExperimentStartHelp": "Leave the field empty if you want to start the A/B test as soon as this A/B test is embedded into your project. Make sure to finish configuring this A/B test before the scheduled starting date. It is not recommended to change an A/B test once it has been started as it could lead to misinterpretations about the results. The specified date will be assumed to be in %1$sUTC%2$s timezone.",
    "FieldScheduleExperimentFinishHelp": "Leave the field empty if you want to finish the A/B test manually. If specified, this A/B test will end automatically on the finish date. If you schedule the A/B test to be finished automatically, make sure to run this A/B test long enough so the results will be real and not due to randomness. The specified date will be assumed to be in %1$sUTC%2$s timezone.",
    "FieldScheduleExperimentFinishLabel": "Finish A/B test on",
    "FieldPercentageParticipantsLabel": "Percentage of visitors who enter this A/B test",
    "FieldPercentageParticipantsHelp": "Specify how many of your visitors should enter this A/B test. If you select 70%, then 70% of all your visitors will enter this A/B test and see either the original version or any variation. The other 30% won't enter the A/B test and they will always see the original version.",
    "FieldPercentageVariationsLabel": "Percentage of traffic allocated to each variation",
    "FieldPercentageVariationsHelp": "It is recommended to show each variation to an equal amount of visitors (default) but you can change the percentage for each variation. The sum of all variations, including the original version should be 100%. Make sure some traffic is always allocated to the original version.",
    "FieldVariationsHelp": "Variations is the term for any new version (variation) you will test against the original (current) version. For example if you want to test different button colors against each other, create one variation for each color you want to compare. The variation names may be visible to your users in the source code or URL. Use only alpha numeric characters without any space or special characters. Max 50 characters can be used per variation name.",
    "ErrorVariationAllocatedNot100Traffic": "You have allocated more than 100% across all variations. Please lower the percentage of traffic allocated to your variations so the total is 100%.",
    "ErrorVariationAllocatedNotEnoughOriginal": "We detected the original version gets much less traffic than it would be by default. We recommend to increase the allocated traffic to the original version by lowering the percentage allocated to other variations.",
    "EqualsDateInYourTimezone": "This equals the following date in your timezone:",
    "Filter": "Filter",
    "CurrentTimeInUTC": "The current time in UTC is",
    "NoExperimentsFound": "There are no A/B tests with this status.",
    "DeleteExperimentInfo": "Delete A/B test. It will not be possible to restore the A/B test.",
    "ViewReportInfo": "View report for this A/B test.",
    "ArchiveReportInfo": "Archive A/B test. When you archive the A/B test, it will not be deleted but the A/B test will not be available anymore in the Report UI or for segmentation.",
    "ArchiveReportConfirm": "Are you sure you want to archive this A/B test? The A/B test will not be shown in the reports and cannot be used for segmentation once it has been archived.",
    "DeleteExperimentConfirm": "Are you sure you want to delete this A/B test? Once an A/B test has been deleted it will not be possible to restore it.",
    "UrlParameterValueToMatchPlaceholder": "Value to match for URL parameter name",
    "TargetPageTestTitle": "URL validator",
    "TargetPageTestLabel": "Enter a full URL including the protocol to check if a visitor will enter the A/B test on this URL:",
    "TargetPageTestErrorInvalidUrl": "Enter a URL including a protocol.",
    "TargetPageTestUrlMatches": "A visitor will enter this A/B test on this URL",
    "TargetPageTestUrlNotMatches": "A visitor will not enter this A/B test on this URL",
    "ExperimentCreatedInfo1": "The A/B test is scheduled to start on",
    "ExperimentCreatedInfo2": "and will run until",
    "ExperimentCreatedInfo3": "Make sure to make all needed changes before the A/B test will start as it is not recommended to change the A/B test once it has been started.",
    "ExperimentRunningInfo1": "This A/B test has been started on",
    "ExperimentRunningInfo2": "and is scheduled to finish on",
    "ExperimentRunningInfo3": "We recommend not to make any change to a running A/B test as it could lead to misinterpretations about the results.",
    "ExperimentFinishedInfo1": "This A/B test is finished. We recommend not to make any change to a finished A/B test as it could lead to misinterpretations about the results. ",
    "ExperimentFinishedInfo2": "Make sure to remove any embedded code for this A/B test from your website, app or server.",
    "RelatedActions": "From here you might want to perform one of these actions",
    "ExperimentWillStartFromFirstTrackingRequest": "This A/B test will start automatically as soon as this A/B test is embedded into your project unless you have configured a scheduled date. Make sure to make all needed configurations upfront as it is not recommended to change an experiment once it has been started.",
    "Rule": "Rule",
    "RunExperimentWithJsClient": "Running an A/B test in the browser with the Matomo JavaScript Tracker",
    "RunExperimentWithJsTracker": "Running an A/B test for a website on the server",
    "RunExperimentWithOtherSDK": "Running an A/B test in an application on iOS, Android, PHP, Java, C#, Python, ... ",
    "RunExperimentWithEmailCampaign": "Running an A/B test in a campaign (eg. ad campaigns, email campagins)",
    "StatusRunning": "Running",
    "StatusArchived": "Archived",
    "StatusFinished": "Finished",
    "StatusCreated": "Created",
    "StatusActive": "Active",
    "Status": "Status",
    "StartDate": "Start Date",
    "FinishDate": "Finish Date",
    "Xhours": "%1$s hours",
    "1Hour": "1 hour",
    "1DayAnd1Hour": "1 day and 1 hour",
    "1DayAndYHours": "1 day and %1$s hours",
    "XDaysAnd1Hour": "%1$s days and 1 hour",
    "XDaysAndYHours": "%1$s days and %2$s hours",
    "NoActiveExperimentConfigured": "There is no active A/B test.",
    "GettingStarted": "Getting started",
    "ExperimentIsFinishedPleaseRemoveCode": "As the A/B test has been finished make sure to remove any embedded code for this A/B test from your website, app or server.",
    "Redirects": "Redirects",
    "FieldExperimentNameHelp": "The name is a unique name for this A/B test. The chosen name may be visible to your users in the source code or URL when running the A/B test. Use only alpha numeric characters without any space or special characters. Max %1$s characters are allowed.",
    "FieldHypothesisHelp": "The hypothesis  explains what you predict to happen when you run the A/B test, what the outcome will be and why it will happen. For example \"%1$sIf%2$s I change the buy now button color, %3$sthen%4$s I am hoping to sell more products %5$sbecause%6$s the button will be more visible.\". The hypothesis is an important step in defining your A/B test and we recommend to take some time to think about it.",
    "FieldHypothesisPlaceholder": "eg 'If I change the buy now button color, then I am hoping to sell more products because the button will be more visible.'",
    "FieldDescriptionHelp": "This field is used to describe which things will be compared. For example \"Comparing blue and red buy now button color\".",
    "FieldDescriptionPlaceholder": "eg 'Comparing blue and red buy now button color'",
    "ActivateExperimentOnAllPages": "Visitors enter this A/B test on any page",
    "ActiveExperimentOnSomePages": "Visitors enter this A/B test when URL equals",
    "NavigationBack": "Back",
    "Schedule": "Schedule",
    "EmbedCode": "Embed code",
    "Definition": "Definition",
    "UpdatingData": "Updating data...",
    "FormCreateExperimentIntro": "An A/B test lets you compare different versions and see which one performs better. These fields are required in order to create an A/B test. Once the A/B test has been created you will be able to customize it further.",
    "FieldConfidenceThresholdHelp": "The goal of an A/B test is to make sure you collect enough data to confidently make changes based on the results of this A/B test. The higher the number, the more likely it is that the results are real, repeatable, and not due to random chance.",
    "FieldMinimumDetectableEffectHelp1": "The minimum detectable effect is the relative minimum improvement that you expect to detect. For example if the conversion rate of a goal is currently 10%, and you expect a 20% MDE, then a variation will need to have a conversion rate of at least 12% in order to be a winning variation.",
    "FieldMinimumDetectableEffectHelp2": "If you expect a small effect we recommend to choose 10%, for a medium effect choose 40% and for a large effect choose 70%.",
    "FieldSuccessConditionsHelp": "We use the minimum detectable effect and the confidence threshold (statistical significance) to calculate the amount of visitors needed before you can be confident about the results. During the lifetime of an A/B test you might see many different potentially winners that achieve the desired effect. However, you need to run the A/B test long enough to ensure the detected effect is not due to randomness.",
    "NewExperimentTargetPageHelp": "By default, an A/B test will be executed on all of your pages. Alternatively, you can choose to execute the A/B test only on a specific page. If you specify a domain including an optional path the A/B test will be only executed on that page. Once the A/B test has been created you can include and exclude more pages.",
    "NeedHelp": "Need help?",
    "TargetPages": "Target Pages",
    "TrafficAllocation": "Traffic Allocation",
    "ActionViewReport": "View report",
    "ActionFinishExperiment": "Finish A/B test",
    "ActionArchiveExperiment": "Archive A/B test",
    "ActionArchiveExperimentSuccess": "A/B test successfully archived",
    "ActionEditExperimentAnyway": "Edit the A/B test anyway",
    "ConfirmUpdateStartsExperiment": "The scheduled start date is in the past which means the A/B test will start immediately. Are you sure you want to start this A/B test? We recommend to not change an A/B test once it has been started as it could lead to misinterpretations about the results.",
    "ConfirmFinishExperiment": "Are you sure you want to finish this A/B test now? It will not be possible to start this A/B test again once it has been finished. Don't forget to remove the code for this A/B test from your project so your visitors will no longer enter the A/B test.",
    "ExperimentRequiresUpdateBeforeViewEmbedCode": "You have unsaved changes for this A/B test. Please save or cancel your changes to view the embed code.",
    "NoActiveExperiment": "There is no A/B test running or finished.",
    "HowToGetStartedUserAccess": "Please ask a user with write access to create a new A/B test under the \"Administration\" menu.",
    "HowToGetStartedAdminAccess": "You can %1$screate a new A/B test now%2$s.",
    "Preview": "Sample report",
    "ExperimentReportPreview": "Here is an example of a report that will be displayed once an A/B test has been started.",
    "CreateNewExperiment": "Create new A/B test",
    "CreateNewExperimentNow": "Create a new A/B test now",
    "EditExperiment": "Edit A/B test %s",
    "EditThisExperiment": "Edit A/B test",
    "ManageExperiments": "Manage A/B tests",
    "ManageExperimentsIntroduction": "An A/B test lets you compare different versions and see which variation makes you more successful. A/B tests are also known as experiments or split tests. In an A/B test you show two or more variations to your visitors and the variation that performs better wins. When a visitor enters the A/B test a variation will be randomly chosen and the visitor will see this variation for all subsequent visits. Experimenting in this way lets you maximise your success.",
    "MenuTitleExperiment": "A/B test \"%1$s\"",
    "ExperimentCreated": "The A/B test has been successfully created. Now you can configure it further. We recommend to take a look at \"Success metrics\".",
    "ExperimentUpdated": "The A/B test has been successfully updated.",
    "ExperimentStarted": "The A/B test has been successfully started.",
    "ExperimentFinished": "The A/B test has been successfully finished.",
    "Hypothesis": "Hypothesis",
    "MinimumDetectableEffectMDE": "Minimum Detectable Effect (MDE)",
    "ExpectedImprovement": "Expected Minimum Detectable Effect",
    "ConfidenceThreshold": "Confidence Threshold",
    "ReportStatusRunning": "The A/B test has been running for %1$s since %2$s.",
    "ReportStatusFinished": "The A/B test has been finished. It ran for %1$s from %2$s to %3$s.",
    "ReportWhenToDeclareWinner": "When to declare a winner? This A/B test report might indicate a winning or losing variation but it is crucial to run A/B tests for at least one or two full business cycles. As user's behaviour varies at different times and days of the week we recommend to run A/B tests for full days or often better full weeks to ensure the detected effect is not due to randomness.",
    "ReportDateCannotBeChanged": "The date for an A/B test report cannot be changed",
    "TargetTypeIsAny": "is any",
    "TargetTypeIsNot": "not %s",
    "TargetTypeEqualsExactly": "equals exactly",
    "TargetTypeEqualsExactlyInfo": "The value has to match exactly, including the URL protocol, search query and hash.",
    "TargetTypeEqualsSimple": "equals simple",
    "TargetTypeEqualsSimpleInfo": "The URL will match any protocol (eg http and https) with or without \"www.\" subdomain. Any trailing slash in the path as well as the search query and hash part of the URL will be ignored when matching the URL.",
    "TargetTypeContains": "contains",
    "TargetTypeExists": "exists",
    "TargetTypeStartsWith": "starts with",
    "TargetTypeRegExp": "matches the regular expression",
    "TargetTypeRegExpInfo": "Any regular expression, for example \"^(.*)test(.*)$\".",
    "TargetComparisionsCaseInsensitive": "All comparisons are evaluated case insensitive.",
    "TargetComparisons": "Comparisons",
    "TargetAttributeUrl": "URL",
    "TargetAttributePath": "Path",
    "FilesystemDirectory": "directory",
    "TargetAttributeUrlParameter": "URL Parameter",
    "TargetAttributeUrlParameterExample": "nameOfUrlParameter",
    "Manage": "Manage",
    "Experiment": "A/B test",
    "Experiments": "A/B Tests",
    "ExperimentName": "A/B test name",
    "ExperimentOverview": "A/B test overview",
    "Variation": "Variation",
    "Variations": "Variations",
    "VariationName": "Variation name",
    "VariationRedirectUrl": "Variation URL",
    "VariationPercentage": "Variation percentage",
    "PercentageParticipants": "Percentage participants",
    "SuccessConditions": "Success conditions",
    "SuccessMetric": "Success metric",
    "SuccessMetrics": "Success metrics",
    "SuccessMetricDetails": "Success metric details",
    "Target": "Target",
    "IncludedTargets": "Included targets",
    "ExcludedTargets": "Excluded targets",
    "AverageX": "Average %1$s",
    "VisitEnteredExperiment": "Visit entered A/B test",
    "VisitorEnteredNExperiments": "Visitor entered %1$s A/B tests",
    "VisitorEnteredOneExperiment": "Visitor entered one A/B test",
    "VisitsActivelyEntered": "Visits actively entered",
    "UniqueVisitorsActivelyEntered": "Unique visitors actively entered"
  }
}
